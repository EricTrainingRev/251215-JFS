# AI Enabled Engineering Quick Reference Guide

## Intro to AI and ML
**Artificial Intelligence (AI)** is the field of creating systems that can perform tasks typically requiring human intelligence, such as reasoning, learning, and perception. **Machine Learning (ML)** is a subset of AI focused on algorithms that learn from data to make predictions or decisions. ML includes supervised, unsupervised, and reinforcement learning. Key objectives are to automate decision-making, extract insights from data, and enable adaptive systems.

## LLM Overview
**Large Language Models (LLMs)** are advanced AI models trained on vast collections of text to understand and generate human language. They use deep learning architectures (e.g., transformers) to process context, answer questions, summarize, translate, and generate code or text. LLMs are evaluated on accuracy, fluency, and relevance. They can be fine-tuned for specific domains and tasks, but require careful prompt design and validation.

## Prompt Engineering
**Prompt Engineering** is the practice of designing and refining input prompts to guide LLMs toward desired outputs. Effective prompts are clear, specific, and context-rich. Techniques include:
- Providing examples (few-shot learning)
- Using explicit instructions
- Iteratively refining prompts based on model responses
Prompt engineering is critical for maximizing LLM performance and minimizing ambiguity or undesired results.

## AI Tooling
AI tooling includes platforms and libraries for building, deploying, and monitoring AI/ML solutions. Common tools:
- **Frameworks**: TensorFlow, PyTorch, scikit-learn
- **Deployment**: Docker, Kubernetes, cloud AI services (AWS, Azure, GCP)
- **Experiment Tracking**: MLflow, Weights & Biases
- **Data Labeling**: Labelbox, Prodigy
Tooling supports reproducibility, scalability, and collaboration in AI projects.

## GitHub Copilot
**GitHub Copilot** started as a code-completion tool but has since evolved into a framework for AI Agent operations. Initially the platform provided code completion suggestions, but has since embedded the ability to chat with LLMs that take on different roles. The standard roles currently include the following:
- ask -> AI has read access to your workspace and acts like a typical chat bot responding to your queries
- edit -> AI has read and write access to your workspace and makes changes to your files based on your queries
- agent -> AI has read and write access to your workspace and tools that provide 3rd party access to external resources
- plan -> AI has read access to your workspace and forms a plan based on your queries that can be iterated on in other modes

## Hallucinations
**Hallucinations** are plausible but incorrect or fabricated outputs generated by LLMs. Causes include insufficient training data, ambiguous prompts, or model overconfidence. Hallucinations can affect factual accuracy, code correctness, and trust. Mitigation strategies:
- Validate outputs against trusted sources
- Use explicit prompts and constraints
- Apply post-processing or human review

## Responsible Use of AI Tools
Responsible AI use involves ethical, legal, and social considerations:
- Ensure transparency and explainability
- Avoid bias and discrimination
- Protect privacy and data security
- Comply with regulations and organizational policies
Document model limitations and monitor for unintended consequences.

## Security Considerations
AI systems introduce new security risks:
- **Data poisoning**: Malicious data corrupts model training
- **Model inversion**: Attackers infer sensitive training data
- **Prompt injection**: Manipulated prompts cause harmful outputs
- **Supply chain risks**: Vulnerabilities in dependencies or pre-trained models
Mitigate risks with secure data pipelines, access controls, and regular audits.

## Code Optimization
AI can assist in code optimization by:
- Suggesting performance improvements
- Identifying redundant or unreachable code
- Recommending best practices
Use static analysis tools, profiling, and AI-powered code review to enhance code quality and maintainability.

## Code Generation
LLMs can generate code from natural language descriptions, templates, or examples. Applications include:
- Boilerplate code creation
- Test case generation
- API client scaffolding
Review generated code for correctness, security, and maintainability. Combine with human expertise for best results.

## Test Generation
AI tools can automate test generation by:
- Creating unit, integration, and system tests from code or requirements
- Generating test data and edge cases
- Identifying untested code paths
Integrate AI-generated tests with CI/CD pipelines and review for coverage and relevance.

# Documentation
- [Github Copilot Documentation](https://docs.github.com/en/copilot)
- [Visual Studio Code GitHub Copilot Documentation](https://code.visualstudio.com/docs/copilot/overview)
- [Prompt Engineering](https://www.promptingguide.ai/techniques)
